{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Single Preceptron\n"
      ],
      "metadata": {
        "id": "UemGHQDsuVAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class Preceptron:\n",
        "\n",
        "  def __init__(self, num_inputs,thre):\n",
        "    self.weights = [0.0]*num_inputs\n",
        "    self.bias = 0.0\n",
        "    self.thre=thre\n",
        "\n",
        "  def predict(self, inputs):\n",
        "    weighted_sum = sum(w * x for w, x in zip(self.weights, inputs))+ self.bias\n",
        "\n",
        "\n",
        "\n",
        "    # output = 1 if weighted_sum > 0 else 0 - step function\n",
        "    output = 1/(1+math.exp(-weighted_sum)) # SIGMOID FUNCTION\n",
        "\n",
        "    return 1 if output>self.thre else 0\n",
        "\n",
        "  def train(self, training_data, targets, learning_rate, epochs):\n",
        "    for epoch in range(epochs):\n",
        "      for inputs , target in zip(training_data, targets):\n",
        "        prediction = self.predict(inputs)\n",
        "        error = target - prediction\n",
        "\n",
        "        for i in range(len(self.weights)):\n",
        "          self.weights[i] += learning_rate * error *inputs[i]\n",
        "          self.bias += learning_rate* error\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  preceptron = Preceptron(num_inputs = 2, thre =0.5)\n",
        "\n",
        "  training_data = [\n",
        "      [0,0],\n",
        "      [0,1],\n",
        "      [1,0],\n",
        "      [1,1]\n",
        "  ]\n",
        "\n",
        "  targets = [0,0,0,1]\n",
        "\n",
        "  learning_rate = 0.1\n",
        "\n",
        "  epochs= 100\n",
        "\n",
        "  preceptron.train(training_data, targets, learning_rate, epochs)\n",
        "\n",
        "  for inputs in training_data:\n",
        "    prediction = preceptron.predict(inputs)\n",
        "    print(f\"Inputs : {inputs} , Prediction : {prediction}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v7Q41GkueV-",
        "outputId": "4819000d-9afe-4a70-eca5-f3f39021d80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs : [0, 0] , Prediction : 0\n",
            "Inputs : [0, 1] , Prediction : 0\n",
            "Inputs : [1, 0] , Prediction : 0\n",
            "Inputs : [1, 1] , Prediction : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shallow Neural Network\n"
      ],
      "metadata": {
        "id": "DopSOlEV4uM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "class ShallowNeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.weights_input_hidden = self.initialize_weights(input_size, hidden_size)\n",
        "        self.bias_hidden = [0.0] * hidden_size\n",
        "\n",
        "        self.weights_hidden_output = self.initialize_weights(hidden_size, output_size)\n",
        "        self.bias_output = [0.0] * output_size\n",
        "\n",
        "    def initialize_weights(self, input_size, output_size):\n",
        "        return [[random.uniform(-0.5, 0.5) for _ in range(input_size)] for _ in range(output_size)]\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + math.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def feedforward(self, inputs):\n",
        "        hidden_activations = [self.sigmoid(sum(x * w for x, w in zip(inputs, weights)) + bias) for weights, bias in zip(self.weights_input_hidden, self.bias_hidden)]\n",
        "        output_activations = [self.sigmoid(sum(a * w for a, w in zip(hidden_activations, weights)) + bias) for weights, bias in zip(self.weights_hidden_output, self.bias_output)]\n",
        "        return hidden_activations, output_activations\n",
        "\n",
        "    def train(self, training_data, targets, learning_rate, epochs):\n",
        "        for epoch in range(epochs):\n",
        "            total_error = 0\n",
        "\n",
        "            for inputs, target in zip(training_data, targets):\n",
        "                hidden_activations, output_activations = self.feedforward(inputs)\n",
        "\n",
        "                output_errors = [target[i] - output_activations[i] for i in range(self.output_size)]\n",
        "                total_error += sum(output_errors)\n",
        "\n",
        "                hidden_errors = [output_errors[i] * self.sigmoid_derivative(output_activations[i]) for i in range(self.output_size)]\n",
        "\n",
        "                for i in range(self.hidden_size):\n",
        "                    for j in range(self.output_size):\n",
        "                        self.weights_hidden_output[j][i] += learning_rate * hidden_activations[i] * hidden_errors[j]\n",
        "                        self.bias_output[j] += learning_rate* hidden_errors[j]\n",
        "\n",
        "                for i in range(self.input_size):\n",
        "                    input_error = 0\n",
        "                    for j in range(self.output_size):\n",
        "                      input_error += hidden_errors[j]*self.weights_hidden_output[j][i]\n",
        "                      input_error += self.sigmoid_derivative(hidden_activations[i])\n",
        "\n",
        "                    for j in range(self.hidden_size):\n",
        "                      self.weights_input_hidden[j][i] += learning_rate * inputs[i] * input_error\n",
        "                      self.bias_hidden[j] += learning_rate * input_error\n",
        "\n",
        "\n",
        "            print(f\"Epoch {epoch+1} / {epochs}, total error : {total_error: .6f}\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  neural_network = ShallowNeuralNetwork(input_size = 2, hidden_size = 2, output_size = 1)\n",
        "\n",
        "  training_data = [\n",
        "      [0,0],\n",
        "      [0,1],\n",
        "      [1,0],\n",
        "      [1,1]\n",
        "  ]\n",
        "\n",
        "  targets = [[0],[0],[0],[1]]\n",
        "\n",
        "  learning_rate = 0.1\n",
        "\n",
        "  epochs= 1000\n",
        "\n",
        "  neural_network.train(training_data, targets, learning_rate, epochs)\n",
        "\n",
        "\n",
        "  for inputs in training_data:\n",
        "    _, predicts = neural_network.feedforward(inputs)\n",
        "    print(f\"Inputs: {inputs} Predictions: {predicts}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JVT1kRXOECmM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}